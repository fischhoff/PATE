---
title: "PATE_20180817"
author: "Ilya"
date: "8/17/2018"
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#####install packages
```{r packages, echo=FALSE}
pkgTest <- function(x)
{
  if (x %in% rownames(installed.packages()) == FALSE) {
    install.packages(x, dependencies= TRUE)    
  }
  library(x, character.only = TRUE)
}
neededPackages <- c("dplyr", "ggplot2", "MASS", "gplots", "vcd", "metafor", "multcomp", "lme4", "lmerTest", "nlme", "gamlss.dist", "gamlss", "dplyr", "tibble", "robustlmm")
for (package in neededPackages){pkgTest(package)}

```


###summarize results of screening, based on each screener's results
```{r}
path = "screened_20180918"
files = list.files(path)
out = NULL
a =1
tmp = read.csv(paste0(path, "/", files[a]))
names(tmp)= tolower(names(tmp))
names.tmp = names(tmp)
out = rbind(out, tmp)
for (a in 2:length(files)){
  tmp = read.csv(paste0(path, "/", files[a]))
  names(tmp)= tolower(names(tmp))
  fields = intersect(names(tmp), names(out))
  out = out[,fields]
  #add 
  tmp = tmp[,fields]
  out = rbind(out, tmp)
}
print("number of articles")
dim(out)[1]
#check there is only one row for each paper id number, should be TRUE
dim(out)[1] == length(unique(out$id))

out$include = tolower(out$include)
out$include[out$include == "n"] = "no"
out$include[out$include == "y"] = "yes"
out$include[out$include == "m"] = "maybe"
print("excluded after title and abstract screen")
tab = data.frame(table(out$include))
tab

print("full-text articles 			assessed for eligibility")
tab$Freq[tab$Var1=="yes"]+tab$Freq[tab$Var1=="maybe"]

#compute whether study was included or not 
# include_abstract = rep(NA, dim(out)[1])
# inds.no.abstract = which(out$include == "no")
# include_abstract[inds.no.abstract]
#check those that are blank
blank = subset(out, include == "")
table(blank$screened_by)#these should all be 0

#articles excluded on full text review
df = data.frame(table(out$exclude_reason))
df = subset(df, Var1 != "")
print("articles excluded after full-text screen")
sum(df$Freq)
#reasons for exclusion
table(out$exclude_reason)

#check ones that are no for include and non-blank for include_article_review
#this should be empty
check = subset(out, include == "no" & exclude_reason !="")
check

# subset(out, exclude_reason == "no information on ecosystem effects (host abundance, mortality, not basal area); small stem density")
out$include_article_review = tolower(out$include_article_review)

#records that are no at include should be blank at include_article_review
inds.include1_no = which(out$include=="no")
out$include_article_review[inds.include1_no]=""
table(out$include, out$include_article_review)
#this should be empty -- should have always indicated whether to include an article on full screen of article, for abstracts that were not marked as no at abstract/title stage
df_blank_odd = subset(out, include_article_review == "" & include != "no")
dim(df_blank_odd)

df.include = data.frame(table(out$include_article_review))
df.include = subset(df.include, Var1 !="")
df.include
#check that maybe ("effects...not separable") and no add up to exclude 
print("exclude check")
df.include$Freq[df.include$Var1=="maybe"]+df.include$Freq[df.include$Var1=="no"]

print("include check")#this plus nos (at include_article_review) should add up to number checked full article 
df.include$Freq[df.include$Var1=="yes"]+
  df.include$Freq[df.include$Var1=="maybe -- requested ill"]+
  df.include$Freq[df.include$Var1=="yes -- requested ill"]

#check ones that are yes at include_article_review and something other than yes or maybe at include. this should be empty
inds.include_review_yes = which(out$include_article_review!="maybe" & out$include_article_review !="no" & out$include_article_review !="" )
inds.include_no = which(out$include=="no")
intersect(inds.include_review_yes, inds.include_no)

#check that all the ones that have exclude reason are also no for include_article_review
table(out$include_article_review, out$exclude_reason)

#check rows that are yes on include_article_review and have entry for exclude_reason -- these need to be corrected for consistency in original data so that this is empty  
test = subset(out, include_article_review=="yes" & exclude_reason !="")
test

table(out$include_article_review)
```

####read in studies spreadsheet and remove ones that were later excluded
```{r}
S <- read.csv("meta_data_20180724 - studies.csv")
#unique(S$exclude)
S <- subset(S, is.na(exclude))#record is okay if it is empty, exclude those that are 1
save(S, file = "S.Rdata")
```

###read in measures data and generate a PP --> abund/morbidity row for each abund/morbidity --> ecosystem process record that does not have an accompanying PP --> abund/morbidity
```{r}
P = read.csv("meta_data_20180724 - quant_data.csv")
dim(P)
P = subset(P, is.na(exclude.as.ecosystem.measure))
dim(P)[1]
P = subset(P, !is.na(pathway))
dim(P)[1]
subset(P, is.na(paper.ID))#should be empty
P$have.not.added.double.counting=trimws(P$have.not.added.double.counting)
##find rows for which "have.not.added.double.counting" is non-empty
# D = subset(P, have.not.added.double.counting !="" &
#              (P$pathway == "morbidity to ecosystem fxn" | P$pathway == "abund biomass to ecosystem fxn"))

D = subset(P, have.not.added.double.counting !="")
list1 = sort(unique(D$pathway))
list0 = c("PP to abund biomass",
          "PP to morbidity", 
          "PP to unknown")
# D.not = subset(P, have.not.added.double.counting =="" |
#                               (P$have.not.added.double.counting !="" & P$pathway != "morbidity to ecosystem fxn" & P$pathway != "abund biomass to ecosystem fxn"))

D.not = subset(P, is.na(have.not.added.double.counting))

dim(D)[1]+dim(D.not)[1]                 
out = NULL
a = 1
for (a in 1:dim(D)[1]){
  tmp = D[a,]
  tmp$have.not.added.double.counting = ""
  tmp.1 = tmp
  index = which(list1 == tmp$pathway)
  tmp.1$measure.general = tmp.1$morbid_or_abund_biomass_measure
  tmp.1$pathway = list0[index]
  tmp.both = rbind(tmp, tmp.1)#both rows
  out = rbind(out, tmp.both)
}
P = rbind(D.not, out)
save(P, file = "P.Rdata")
```

####combine study and measures data 
###includes error check that identifies couple of papers inadvertantly reviewed twice.  
##fields in PATE_data.csv:
##paper.ID: unique identifier for each paper (matches numbers in each screener's file)
##author: study lead author
##Pathogen.kingdom; Host.kingdom: note that there are some entries here for entities that are higher or lower than kingdom or (e.g. dinoflagellates) paraphyletic. We may want to limit analysis to categories that appear relatively frequently. 
###System: aquatic, terrestrial
###System.2: if we decide to use this we may want to bin these into fewer categories of biomes
###PP.to.ecosystem.fxn: 1 (pathway present), 0 (absent); this describes direct effect of PP on ecosystem function, e.g. biomass of trematodes, primary production of hemiparasitic plants
###"PP.abundance": this seems lower priority for analysis, refers to whether study included info on abundance of PP in the environment
###"PP.morbidity": did the study contain info on the phenotype of pathogens (e.g. vigor of hemiparasitic plants). this seems lower priority for inclusion in analysis. 
###"PP.to.host.infection.prevalence...intensity": does the paper report on PP infection prevalence or intensity? lower priority for analysis
###"PP.to.abund.biomass", "PP.to.morbidity", "PP.to.unknown": does paper report on each of these pathways from PP to host/community. Unknown includes cases where it is not possible to determine whether effects are on abund/biomass or on morbidity
###"abund.biomass.to.ecosystem.fxn", "morbidity.to.ecosystem.fxn", "unknown.to.ecosystem.fxn": does paper report on each of these pathways
###abiotic.or.biotic: does paper report on abiotic or biotic factors that mediate influence of PP on other components in model? 
###"experimental..PP.manipulation.or.mimic...1..observational..2..both..3.": is paper experimental, observational, or both; note entries in this field currently include some notes and would need to be cleaned up to be used in analysis. 
###"process.vs..standing.stock.vs..both": does paper report on ecosystem effects as process (e.g. rate), standing stock, or report on both? 
###"highest.observational.scale..species.vs..community.ecosystem..of.ecosystem.impact": what is the highest observational scale at which ecosystem function effects have been measured: species, assemblage (multiple species), or ecosystem (includes papers in which effects at level of a functional group have been measured e.g. biomass of all trees) 
###spatial scale: area or volume of sampling unit; description would require some recoding to be used in analysis 
###"coordinates.in.paper": are lat/long reported in paper (note: have not extracted this info)
###measureID: if a study reported on an ecosystem process measure (e.g. morbidity --> ecosystem fxn), we assumed that there was also a measure at an earlier stage in the conceptual diagram (PP --> morbidity). We created an additional record for this earlier stage, and linked the two stages with a measureID unique to that study. The two measures are also linked by having the same value for "measure.specific....outcome.variable", which is also unique within the study.  
###pathway: what pathway has been measued
###measure.general: in the case of (X --> ecosystem fxn), this is either biogeochemical cycles, primary production, or secondary production. For (PP --> X), there is more variation in how measures have been described, and some recoding would be needed to make these data comparable. 
###"measure.specific....outcome.variable": the measure as described in the paper
###effects.on.host; effects.on.community: was the PP --> X effect on the host or not, on the community or not; note this has not been filled in for all rows but could be based (have checked this for part) on the measure.general and measure.specific
###ecosystem_process_mediate: did an ecosystem process mediate the relationship between PP and other components of the conceptual diagram. Note this has not been filled in throughout, but could be based on other data (have checked this for part) 
```{r}
load("S.Rdata")
load("P.Rdata")

names(S)[names(S)=="ID"]="paper.ID"
setdiff(S$paper.ID, P$paper.ID)
ids = setdiff(P$paper.ID, S$paper.ID)#this has two that determined later needed to be excluded
ids.common = intersect(P$paper.ID, S$paper.ID)#
dim(P)
P = subset(P, paper.ID %in% ids.common)
dim(P)
out = NULL 
uid = unique(P$paper.ID)
a = 37
out = NULL 
for (a in 1:length(uid)){
  tmpS = subset(S, paper.ID == uid[a])
  tmpP = subset(P, paper.ID == uid[a])
  #compute PP.to.abund.biomass
  tmpS$PP.to.abund.biomass=0
  PP_abund = subset(tmpP, pathway == "PP to abund biomass")
  if (dim(PP_abund)[1]>0){
    tmpS$PP.to.abund.biomass=1
  }
  #compute PP.to.morbidity
  tmpS$PP.to.morbidity=0
  PP_morb = subset(tmpP, pathway == "PP to morbidity")
  if (dim(PP_morb)[1]>0){
    tmpS$PP.to.morbidity=1
  }
  
  #compute PP.to.unknown
  tmpS$PP.to.unknown=0
  PP_unk = subset(tmpP, pathway == "PP to unknown")
  if (dim(PP_unk)[1]>0){
    tmpS$PP.to.unknown=1
  }

  #compute abund biomass to ecosystem fxn
  tmpS$abund.biomass.to.ecosystem.fxn=0
  PP_ab_ef = subset(tmpP, pathway == "abund biomass to ecosystem fxn")
  if (dim(PP_ab_ef)[1]>0){
    tmpS$abund.biomass.to.ecosystem.fxn=1
  }

  #compute morbidity to ecosystem fxn
  tmpS$morbidity.to.ecosystem.fxn=0
  PP_m_ef = subset(tmpP, pathway == "morbidity to ecosystem fxn")
  if (dim(PP_m_ef)[1]>0){
    tmpS$morbidity.to.ecosystem.fxn=1
  }

  #compute unknown to ecosystem fxn
  tmpS$unknown.to.ecosystem.fxn=0
  PP_u_ef = subset(tmpP, pathway == "unknown to ecosystem fxn")
  if (dim(PP_u_ef)[1]>0){
    tmpS$unknown.to.ecosystem.fxn=1
  }
  tmpM = merge(tmpS, tmpP, by = "paper.ID")
  out = rbind(out, tmpM)
  
  if (dim(tmpM)[1] > dim(tmpP)[1]){
    #this will print if there are papers that have been entered twice in spreadsheet "studies"
    print("a")
    print(uid[a])
    print(a)
  }
}
M = merge(S, P, by = "paper.ID")
dim(M)[1]==dim(out)[1]
dim(M)

M <- out
save(M, file = "M.Rdata")
write.csv(M, file ="PATE_data.csv")
```

###meta-analysis

###functions
###write function to get pooled value for variable across all "levels" within a study, pathway, and general.measure  
```{r}
b  = 14
c = 3
d = 2
e = 1
one.per.var = function(M.y){
  ustudy = unique(M.y$paper.ID)
  out = NULL
  for (b in 1:length(ustudy)){
  print("b")
  print(b)

    print(ustudy[b])
  s.tmp = subset(M.y, paper.ID == ustudy[b])
  upath = unique(s.tmp$pathway)
#for each pathway in study
    for (c in 1:length(upath)){
      p.tmp = subset(s.tmp, pathway == upath[c])
      umeasure = unique(p.tmp$measure.general)
      print("c")
      print(c)
      #for each general measure, find all variables within that measure
      for (d in 1:length(umeasure)){
        print("d")
        print(d)
        inds = which(p.tmp$measure.general == umeasure[d])
        m.tmp = p.tmp[inds,]
        #unique variable
        uvar = unique(m.tmp$measure.specific....outcome.variable)
        for (e in 1:length(uvar)){
          print("e")
          print(e)

          v.tmp = subset(m.tmp, measure.specific....outcome.variable == uvar[e])
          if (dim(v.tmp)[1]>1){
            #if more than one record for a variable, find pooled estimate across all records     
            print("pooled estimate")
            m = rma(yi = v.tmp$d,
                       vi = v.tmp$d.sampling.variance,
                       measure = "MN")  
            #print(m)
            v.tmp$d = m$yi[1]
            v.tmp$d.sampling.variance = m$vi[1]
            v.tmp = v.tmp[1,]
            
            out = rbind(out, v.tmp)
          }#end if statement
          else {#else use value already gotten
            out = rbind(out, v.tmp)
          }#end else
 
  
          print(v.tmp$d)
          
        }#end variable
        
      }#end general measure
   }#end pathway
  }#end study
  return(out)
}#end function

save(one.per.var, file = "one.per.var.Rdata")

```

###write function to get standard error based on p value and effect size
```{r}
se_from_p <- function(effect, p){
  z = -0.862 + sqrt(0.743 - 2.404*log(p))
  SE = effect/z
  return(SE)
}
save(se_from_p, file = "se_from_p.Rdata")
```

###function to calculate SE for correlation coefficient (r) from r and n (sample size)
###source: Zar, J. 1999. Biostatistical analysis. p. 373
```{r}
se.calc.from.r.n <-  function( r, n){
  se.calc = sqrt((1-r^2)/(n-2))
  return (se.calc)
}
save(se.calc.from.r.n,file="se.calc.from.r.n.Rdata")
```

###function to calculate standardized mean difference (d) from regression coefficient (log odds ratio) and SE of coefficient
```{r}
or_to_d <- function(df){
  log.odds.ratio = df$regression.coefficient
  log.odds.se = df$regression.coefficient.SE
  log.odds.variance = log.odds.se^2
  #https://www.meta-analysis.com/downloads/Meta-analysis%20Converting%20among%20effect%20sizes.pdf
  df$d = log.odds.ratio*(sqrt(3)/pi)
  df$d.sampling.variance=log.odds.variance*(3/pi^2)
  return(df)
}
save(or_to_d, file = "or_to_d.Rdata")
```

###function to calculate standardized mean difference (d) from correlation coefficient (r) and SE of r
```{r}
r_to_d <- function(df ){
      r = df$correlation.coefficient
      r2 = r^2
      d = 2*r/sqrt(1-r2)
      #Standard deviation (s) = Standard Error * √n 
      print(as.numeric(as.character(df$correlation.coefficient.se)))
      s_r = as.numeric(as.character(df$correlation.coefficient.se))*sqrt(df$sample.size.total)
      var_r = s_r^2
      var_d = 4*var_r/((1-r2)^3)
      #from d and var_d to log odds ratio
      df$d =d
      df$d.sampling.variance = var_d
      df2 <-df
  return(df2)
}
save(r_to_d, file = "r_to_d.Rdata")
```

#fix P values that have characters in them
```{r}
load("M.Rdata")

M$P = as.character(M$P)
P = as.numeric(M$P)
inds.na = which(is.na(P))
is.not.empty = which(M$P !="")
inds.na = intersect(inds.na, is.not.empty)
a = 1
for (a in 1:length(inds.na)){
  M$P[inds.na[a]]=strsplit(M$P[inds.na[a]],"<")[[1]][2]
  print(M$P[inds.na[a]])
}
M$P = as.numeric(M$P)
save(M, file = "M.Rdata")
```


###following chunks each handle one data type encountered in papers, and convert that data type to d (standardized mean difference) and sampling variance in d


###mean_variance
###exclude data points with standard deviation equal to zero
###includes parasite/pathogen removal (as control)
###includes less vs. more virulent form of disease
###includes only "control" treatments (invaded vs. uninvaded), in cases where host abundance was manipulated at local scale on top of effect of pathogen on host abundance (Connelly et al._2093)

```{r mean_variance}
load("M.Rdata")
load("one.per.var.Rdata")

# sd_adjust = 0.0001
M = subset(M, pathway %in% c("morbidity to ecosystem fxn",
                             "unknown to ecosystem fxn",
                             "abund biomass to ecosystem fxn",
                             "PP to ecosystem fxn"))
#M = subset(M, exclude.as.ecosystem.measure !=1)
M$d = NA
M$control_sd=NA
M$infected_sd = NA
M$d = NA
M$d.sampling.variance = NA
M$control.mean=as.numeric(as.character(M$control.mean))
M$infected.mean=as.numeric(as.character(M$infected.mean))
unique(as.character(M$sample.size.infected))
M$sample.size.infected=as.numeric(as.character(M$sample.size.infected))
M.y = subset(M, (data.to.use == "mean_variance" | data.to.use == "mean_variance levels of disease" ) 
             & !is.na(control.mean))
M.n  = subset(M, (data.to.use != "mean_variance" & data.to.use != "mean_variance levels of disease") | ((data.to.use == "mean_variance" | data.to.use == "mean_variance levels of disease") & is.na(control.mean)))
dim(M.y)[1]+dim(M.n)[1]==dim(M)[1]
#for each record, get effect size and SE
a = 31
#M.y = subset(M.y, paper.ID == 1924)
for (a in 1:dim(M.y)[1]){
  #find out what type of variance measure is there
  var_measure = M.y$variance.measure[a]
  if (var_measure == "SD"){
    M.y$control_sd[a]=M.y$control.variance[a]
    M.y$infected_sd[a]=M.y$infected.variance[a]
  }
  if (var_measure == "SE"){
    M.y$control_sd[a]=M.y$control.variance[a]*sqrt(M.y$sample.size.control[a])
    M.y$infected_sd[a]=M.y$infected.variance[a]*sqrt(M.y$sample.size.infected[a])
  }
  if (var_measure == "CV"){
    M.y$control_sd[a] = M.y$control.variance[a]*M.y$control.mean[a]/100
    M.y$infected_sd[a] = M.y$infected.variance[a]*M.y$infected.mean[a]/100
  }
  
  if (var_measure == "CI"){
    control.se = (M.y$control.CI.upper[a] - M.y$control.mean[a])/1.96
    M.y$control_sd[a]= control.se * sqrt(M.y$sample.size.control[a])

    infected.se = (M.y$infected.CI.upper[a] - M.y$infected.mean[a])/1.96        
    M.y$infected_sd[a]= infected.se * sqrt(M.y$sample.size.infected[a])
    }
  m1i = M.y$control.mean[a]
  m2i = M.y$infected.mean[a]
  sd1i = M.y$control_sd[a]
  sd2i = M.y$infected_sd[a]
  # if (sd1i == 0 | sd2i == 0){
  #   sd1i = sd1i+sd_adjust
  #   sd2i = sd2i+sd_adjust
  # }
  n1i = M.y$sample.size.control[a]
  n2i = M.y$sample.size.infected[a]
  m = escalc(measure = "SMD",
         m1i = m1i,
         m2i = m2i,
         sd1i = sd1i,
         sd2i = sd2i,
         n1i = n1i,
         n2i = n2i)
  M.y$d[a] =m$yi[1]
  #print("a")
  #print(a)
  #print(M.y$d[a])
  M.y$d.sampling.variance[a] = m$vi[1]
}

ustudy = unique(M.y$paper.ID)
#for each study
out = one.per.var(M.y)

dim(out)

M = rbind(M.n, out)
out$d
out$d.sampling.variance
out$paper.ID
save(M, file = "M.Rdata")


####brainstorming, more complicated version, not doing
#find number of variables and number of secondary factors for each variable
#for each variable and each secondary, etc. factor within that variable
#if number of secondary, etc. factors is three
#for each quaternary factor, find the pooled estimate for all records across that quaternary factor, save to output including pooled estimates for tertiary factors
#if one variable and no secondary_factors, use effect size and SE for that record
#else if one variable and secondary variables within that
#if more than one variable, then for each variable:
#find whether secondary_factor, tertiary_factor, quaternary_factor have been filled in
#if secondary_factor filled in, then get  pooled estimate across all variables within that measure.
#if there are more than one variable within that measure
#if there is a secondary level within , get pooled estimate for all records within that  
```

###t and sample sizes and p
```{r}
load("M.Rdata")
load("se_from_p.Rdata")
load("one.per.var.Rdata")
#d = t*sqrt((nt+nc)/nt*ntc)#formula from p. 200 of Koricheva et al. 2013
M.y = subset(M, data.to.use == "t and sample sizes and p")
M.n = subset(M, data.to.use != "t and sample sizes and p")
M.y$P=as.character(M.y$P)
M.y$P[M.y$P=="<0.0005"]=0.0005
M.y$P = as.numeric(M.y$P)
unique_vars = length(unique(M.y$measure.specific....outcome.variable))
dimM = dim(M.y)[1]
if (dimM==unique_vars){
  print("okay")  
} else {
  #for each record
  for (a in 1:dimM){
    M.y$d[a] = M.y$t[a] * sqrt((M.y$sample.size.control[a] + M.y$sample.size.infected[a])/
                              (M.y$sample.size.control[a] * M.y$sample.size.infected[a]))
    se = se_from_p(M.y$d[a],M.y$P[a])
    #http://mathworld.wolfram.com/StandardError.html
    M.y$d.sampling.variance[a]=se^2
    if (!is.na(M.y$variable.greater.without.pathogen.parasite[a])){
      if(M.y$variable.greater.without.pathogen.parasite[a]==1){
        M.y$d[a]=M.y$d[a]*-1
      }
    }
  }
}
M.y.2 = one.per.var(M.y)
M.y.2$d
M.y.2$d.sampling.variance
M.n$P = as.numeric(as.character(M.n$P))

M = rbind(M.n, M.y.2)
save(M, file = "M.Rdata")
```


###R2 and direction and sample size
```{r}
load("se.calc.from.r.n.Rdata")#fxn to get SE from r and n
load("r_to_d.Rdata")#function to get d, var.d from r
load("one.per.var.Rdata")
load("M.Rdata")
M$correlation.coefficient.se = NA
M.n = subset(M,data.to.use!="R2 and direction and sample size")
M.y = subset(M,data.to.use=="R2 and direction and sample size")

#M.y.se =subset(M.y, R-squared-se !="") 
#M.y.nose =subset(M.y, R-squared-se !="") 
lev = dim(M.y)[1]
for (c in 1:lev){
      ri = as.numeric(as.character(M.y$R.squared[c]))#get inputs for rma
      ri = sqrt(ri)
      ri = ri*as.numeric(as.character(M.y$direction[c]))#multiply by 1 or -1
      M.y$correlation.coefficient[c]=ri
      ni = M.y$sample.size.total[c]
      M.y$correlation.coefficient.se[c] = se.calc.from.r.n(ri, ni)#get SE
      M.y[c,]=r_to_d(M.y[c,])
}
print("d")
M.y$d
print("variance")
M.y$d.sampling.variance

#for each study
out = one.per.var(M.y)
M = rbind(out, M.n)
save(M, file = "M.Rdata")


```


###correlation coefficient and sample size and P
###use P to calculate SE
```{r}
load("se.calc.from.r.n.Rdata")#fxn to get SE from r and n
#load("se_from_p.Rdata")#fxn to get SE from P
load("r_to_d.Rdata")#function to get d, var.d from r
load("one.per.var.Rdata")
load("M.Rdata")
M$correlation.coefficient.se = NA
M.n = subset(M,data.to.use!="correlation coefficient and sample size and P")
M.y = subset(M,data.to.use=="correlation coefficient and sample size and P")
# M.y$P = as.character(M.y$P)
# M.y$P[M.y$P == "<0.001"]="0.001"
# M.y$P = as.numeric(M.y$P)

lev = dim(M.y)[1]
for (c in 1:lev){
      ri = as.numeric(as.character(M.y$correlation.coefficient[c]))#get inputs for rma
      ni = M.y$sample.size.total[c]
      P = M.y$P[c]
      #M.y$correlation.coefficient.se[c] = se_from_p(ri, P)#get SE#this results in even larger variance
      M.y$correlation.coefficient.se[c] = se.calc.from.r.n(ri, ni)#get SE
      M.y[c,]=r_to_d(M.y[c,])
}


#for each study
out = one.per.var(M.y)
out$d
out$d.sampling.variance

M = rbind(out, M.n)
save(M, file = "M.Rdata")


```

###effect and raw predictor
###perform linear model between predictor and effect. model coefficient and standard errors are log odds and log standard error for the effect of interest. convert these values to d, variance in d  
#note: have not attempted to fix so that negative effects of PP have negative effect size
```{r}
load("M.Rdata")
M.y = subset(M, data.to.use == "effect and raw predictor")
M.y$predictor.value=as.character(M.y$predictor.value)
M.y$predictor.value[M.y$predictor.value=="–"]=NA
M.y$predictor.value=as.numeric(M.y$predictor.value)
M.y = subset(M.y, !is.na(predictor.value))
M.n = subset(M, data.to.use != "effect and raw predictor")
#str(M.y$infected.mean)
b = 1
c = 1
d = 1
e = 1
one.per.var.regression = function(M.y){
  ustudy = unique(M.y$paper.ID)
  out = NULL
  for (b in 1:length(ustudy)){
  s.tmp = subset(M.y, paper.ID == ustudy[b])
  upath = unique(s.tmp$pathway)
#for each pathway in study
    for (c in 1:length(upath)){
      p.tmp = subset(s.tmp, pathway == upath[c])
      umeasure = unique(p.tmp$measure.general)
      #for each general measure, find all variables within that measure
      for (d in 1:length(umeasure)){
        inds = which(p.tmp$measure.general == umeasure[d])
        m.tmp = p.tmp[inds,]
        #unique variable
        uvar = unique(m.tmp$measure.specific....outcome.variable)
        for (e in 1:length(uvar)){
          # print("e")
          # print(e)
          v.tmp = subset(m.tmp, measure.specific....outcome.variable == uvar[e])
            #if more than one record for a variable, find pooled estimate across all records
            #print(v.tmp$d)
            m = lm(infected.mean ~ predictor.value,
                       data = v.tmp,
                   na.action = na.omit)
            #print(m)
            log.odds.ratio = m$coefficients[1]
            log.odds.se = coef(summary(m))[2,"Std. Error"]
            log.odds.variance = log.odds.se^2
            #https://www.meta-analysis.com/downloads/Meta-analysis%20Converting%20among%20effect%20sizes.pdf
            v.tmp$d = log.odds.ratio*(sqrt(3)/pi)
            v.tmp$d.sampling.variance=log.odds.variance*(3/pi^2)
            v.tmp = v.tmp[1,]
            # 
            out = rbind(out, v.tmp)
          # print("b")
          # print(b)
          # print("c")
          # print(c)
          # print("d")
          # print(d)
          # print("e")
          # print(e)
          # print(v.tmp$d)
          
        }#end variable
        
      }#end general measure
   }#end pathway
  }#end study
  return(v.tmp)
}#end function

out = one.per.var.regression(M.y)
out
M = rbind(M.n, out)
save(M, file = "M.Rdata")
```

##one-way ANOVA: calculate effect sizes from F and sample size
##determined we cannot infer positive or negative in effect size if study does not report direction or means, for non-significant results, because F value is always positive.  
#where sample size not reported, assumed equal sample size for infected vs. control, used df = n-k (k = number of groups = 2) to determine sample size total. 
```{r}
load("M.Rdata")
M$d.absolute = 0#is d absolute value
M.y = subset(M, data.to.use == "one-way ANVOA F _ degrees freedom")
M.n = subset(M, data.to.use != "one-way ANVOA F _ degrees freedom")
# P = as.numeric(M.y$P)
# inds.na = which(is.na(P))
# M.y$P = as.character(M.y$P)
# a = 1
# for (a in 1:length(inds.na)){
#   M.y$P[inds.na[a]]=strsplit(M.y$P[inds.na[a]],"<")[[1]][2]
#   print(M.y$P[inds.na[a]])
# }
# M.y$P = as.numeric(M.y$P)
#infer sample size based on df for records without sample size
na.inds = which(is.na(M.y$sample.size.control))
M.y$sample.size.control[na.inds]=(M.y$df[na.inds]+2)/2
M.y$sample.size.infected[na.inds]=(M.y$df[na.inds]+2)/2

#calculate d (effect size) from F and sample size (Koricheva et al. p. 200, F ratio from one-way ANOVA)
for (a in 1:dim(M.y)[1]){
  ni = M.y$sample.size.infected[a]
  nc = M.y$sample.size.control[a]
  M.y$d[a]= sqrt(M.y$F[a]*(ni + nc)/(ni*nc))
  #calculate SE from d and P value 
  d_se = se_from_p(M.y$d[a], M.y$P[a])
  #standard error = square root of the estimated error variance
  var_d = d_se^2
  M.y$d.sampling.variance[a]=var_d
}
M.y$d.absolute=1#these ones are absolute value
print(M.y$d)
print(M.y$d.sampling.variance)
M = rbind(M.n, M.y)
save(M, file = "M.Rdata")
```

###R2 and sample size
###if direction not given for some measures in a study, then exclude direction information for all measures (e.g. Lovett et al. 2010)
```{r}

load("se.calc.from.r.n.Rdata")#fxn to get SE from r and n
load("r_to_d.Rdata")#function to get d, var.d from r
load("one.per.var.Rdata")
load("M.Rdata")
M.n = subset(M,data.to.use!="R2 and sample size")
M.y = subset(M,data.to.use=="R2 and sample size")

lev = dim(M.y)[1]
for (c in 1:lev){
      ri = as.numeric(as.character(M.y$R.squared[c]))#get inputs for rma
      ri = sqrt(ri)
      M.y$correlation.coefficient[c]=ri
      ni = M.y$sample.size.total[c]
      M.y$correlation.coefficient.se[c] = se.calc.from.r.n(ri, ni)#get SE
      M.y[c,]=r_to_d(M.y[c,])
      M.y$d.absolute[c]=1

}
print("d")
print("variance")
M.y$d.sampling.variance

#for each study
out = one.per.var(M.y)
M = rbind(out, M.n)
save(M, file = "M.Rdata")

```


###regression coefficient and SE
##coefficient is equal to log odds ratio. convert log odds ratio to d
```{r}
load("M.Rdata")
load("or_to_d.Rdata")
load("one.per.var.Rdata")
M.y = subset(M, data.to.use == "regression coefficient and SE")
M.n = subset(M, data.to.use != "regression coefficient and SE")

for (a in 1:dim(M.y)[1]){
  M.y[a,]=or_to_d(M.y[a,])
}
M.y = one.per.var(M.y)#in case there are duplicates
print(M.y$d)
print(M.y$d.sampling.variance)
M = rbind(M.y, M.n)
save(M, file = "M.Rdata")
```

###Mann-Whitney U and sample sizes. source: Koricheva et al. 2013 (p. 201)
```{r}
load("se.calc.from.r.n.Rdata")
     # (ri, ni)
load("M.Rdata")
load("r_to_d.Rdata")
load("one.per.var.Rdata")
M.y = subset(M, data.to.use == "Mann-Whitney U and sample sizes")
M.n = subset(M, data.to.use != "Mann-Whitney U and sample sizes")

#C.tmp$z = -0.862 + sqrt(0.743 - 2.404*log(C.tmp$p.value))
#SE.case = C.tmp$case_events/C.tmp$z
for (a in 1:dim(M.y)[1]){
  M.y$sample.size.total[a] = M.y$sample.size.control[a]
  M.y$correlation.coefficient[a] = abs((1 - 2*M.y$U[a])/(M.y$sample.size.control[a]*M.y$sample.size.infected[a]))
  ri = M.y$correlation.coefficient[a]
  ni = M.y$sample.size.control[a]
  M.y$correlation.coefficient.se[a] = se.calc.from.r.n(ri, ni)#get SE#this doesn't work

  M.y[a,]=r_to_d(M.y[a,])
}
M.y = one.per.var(M.y)#in case there are duplicates
print(M.y$d)
print(M.y$d.sampling.variance)
M = rbind(M.y, M.n)
save(M, file = "M.Rdata")


```


###percent difference and P -- don't know how to convert to d, so not doing
```{r}
#calculate effect size from percent change
#calculate SE from effect size and P value
```

###means and P -- don't know how to convert to d, so not doing
```{r means P}
#calculate percent difference between two means. 
#calculate SE based on P
```


#look at representation of pathways and measures in data
```{r}
load("M.Rdata")
M = subset(M, !is.na(d))
length(unique(M$paper.ID))#number of papers
#look at distribution of measures by pathway and measure 
M$pathway = as.character(M$pathway)
M$measure.general = as.character(M$measure.general)
xtabs(~pathway + measure.general, data = M)
#look at distribution of number of observations per paper
xtabs(~paper.ID, data = M)

```

##meta-analysis
#check whether absoluate value of d is normally distributed, and whether log of abs(d) is normal
```{r distributions}
load("M.Rdata")
M = subset(M, pathway != "PP to ecosystem fxn")
dat = M
dat$d = dat$d+0.000001#add small number so that can take log and it be definite
#check normality of d
shapiro.test(dat$d)
qqnorm(dat$d)
shapiro.test(abs(dat$d))
qqnorm(abs(dat$d))
#check normality of log d -- slightly closer to normality but still very much not normal 
shapiro.test(log(abs(dat$d)))

qqnorm(log(abs(dat$d)))

#make histogram for absolute value of d
ggplot(dat, aes(abs(d), fill = pathway) )+
  geom_histogram()

#make histogram for log of absolute value of d
ggplot(dat, aes(log(abs(d)), fill = pathway)) +
  geom_histogram()

```


##use nlme and absolute value of d
##http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer
```{r}
#using package lmerTest to get p values
load("M.Rdata")
M = subset(M, !is.na(d))
M.tmp = subset(M, is.na(d.sampling.variance))
M = subset(M, pathway != "PP to ecosystem fxn")
dat = M
dat$d = dat$d+0.000001

# dat$log.d = log(abs(dat$d))

#construct model so that it goes through origin; use lmeControl so that exact weights are used
res.lme.pathway <- lme(abs(d) ~ pathway-1, random = ~ 1 | paper.ID, weights = varFixed(~ d.sampling.variance), control=lmeControl(sigma = 1), data=dat)
summary(res.lme.pathway)
save(res.lme.pathway, file = "res.lme.pathway.Rdata")

res.lme.pathway.r= residuals(res.lme.pathway)
shapiro.test(res.lme.pathway.r)
#check which pathways are different from each other, if any
summary(glht(res.lme.pathway, linfct=contrMat(c(
  "abund biomass to ecosystem fxn"=1,
  "morbidity to ecosystem fxn"=1,
  "unknown to ecosystem fxn"=1), type="Tukey")), test=adjusted("none"))

#measure
res.lme.measure <- lme(abs(d) ~ measure.general-1, random = ~ 1 | paper.ID, weights = varFixed(~ d.sampling.variance), control=lmeControl(sigma = 1), data=dat)
summary(res.lme.measure)

summary(glht(res.lme.measure, linfct=contrMat(c(
  "biogeochemical cycles"=1,
  "primary production"=1,
  "secondary production"=1), type="Tukey")), test=adjusted("none"))


#this doesn't work because of singularity
# res.lme.pathway.measure <- lme(log.d ~ pathway*measure.general-1, random = ~ 1 | paper.ID, weights = varFixed(~ d.sampling.variance), control=lmeControl(sigma = 1), data=dat)
# summary(res.lme.pathway.measure)

```


##use nlme and log of absolute value of d
##http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer
```{r nlme_log}
#using package lmerTest to get p values
load("M.Rdata")
M = subset(M, !is.na(d))
M.tmp = subset(M, is.na(d.sampling.variance))
M = subset(M, pathway != "PP to ecosystem fxn")
dat = M
dat$d = dat$d+0.000001

# dat$log.d = log(abs(dat$d))

#construct model so that it goes through origin; use lmeControl so that exact weights are used
res.lme.pathway <- lme(log(abs(d)) ~ pathway-1, random = ~ 1 | paper.ID, weights = varFixed(~ d.sampling.variance), control=lmeControl(sigma = 1), data=dat)
summary(res.lme.pathway)
save(res.lme.pathway, file = "res.lme.pathway.Rdata")

res.lme.pathway.r= residuals(res.lme.pathway)
shapiro.test(res.lme.pathway.r)
#check which pathways are different from each other, if any
summary(glht(res.lme.pathway, linfct=contrMat(c(
  "abund biomass to ecosystem fxn"=1,
  "morbidity to ecosystem fxn"=1,
  "unknown to ecosystem fxn"=1), type="Tukey")), test=adjusted("none"))

#measure
res.lme.measure <- lme(log(abs(d)) ~ measure.general-1, random = ~ 1 | paper.ID, weights = varFixed(~ d.sampling.variance), control=lmeControl(sigma = 1), data=dat)
summary(res.lme.measure)

summary(glht(res.lme.measure, linfct=contrMat(c(
  "biogeochemical cycles"=1,
  "primary production"=1,
  "secondary production"=1), type="Tukey")), test=adjusted("none"))


#this doesn't work because of singularity
# res.lme.pathway.measure <- lme(log.d ~ pathway*measure.general-1, random = ~ 1 | paper.ID, weights = varFixed(~ d.sampling.variance), control=lmeControl(sigma = 1), data=dat)
# summary(res.lme.pathway.measure)

```

##use robustlmm::rlmer and log of absolute value of d -- doesn't work with weights, so not appropriate for meta-analysis
##http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer
```{r robustlmm}
#using package lmerTest to get p values
load("M.Rdata")
M = subset(M, !is.na(d))
M.tmp = subset(M, is.na(d.sampling.variance))
M = subset(M, pathway != "PP to ecosystem fxn")
dat = M
dat$d = dat$d+0.000001

# dat$log.d = log(abs(dat$d))

#construct model so that it goes through origin
# res.lme.pathway <- robustlmm::rlmer(log(abs(d)) ~ pathway-1 + (1| paper.ID), weights = 1/d.sampling.variance, data=dat)
# summary(res.lme.pathway)
#Error in robustlmm::rlmer(log(abs(d)) ~ pathway - 1 + (1 | paper.ID), : Argument weights is unsave to use at the momen
```


###fixed effects w/ gamma distribution with lme4
###estimate is very large for one value, small for other two values (for pathway model and for measures model)
```{r}
library(MuMIn)
load("M.Rdata")

M = subset(M, !is.na(d))
M = subset(M, pathway != "PP to ecosystem fxn")
M$paper.ID=factor(M$paper.ID)
dat = M
dat$d = dat$d+0.000001
#intercept - only model
m.g.int <- glm(abs(d) ~1, weights = 1/d.sampling.variance, data=dat,
                 family = Gamma
                 )
summary(m.g.int)

#pathway
m.g.fixed <- glm(abs(d) ~pathway -1, weights = 1/d.sampling.variance, data=dat,
                 family = Gamma
                 )
summary(m.g.fixed)
model.sel(m.g.int, m.g.fixed)
#better fit with pathway than intercept model

m.g.measure <- glm(abs(d) ~measure.general - 1, weights = 1/d.sampling.variance, data=dat,
                 family = Gamma
                 )
summary(m.g.measure)

```


##bootstrap with our data
```{r}
load("M.Rdata")

M = subset(M, !is.na(d))
M = subset(M, pathway != "PP to ecosystem fxn")
M$paper.ID=factor(M$paper.ID)
dat = M
dat$d = dat$d+0.000001

dat.sum <- dat %>%
  group_by(pathway) %>%
  summarize(
            #mean = mean(abs(d),
            sd = sd(abs(d)))
            #max = max(abs(d)))
runs = 100

model.out = NULL
upaper = unique(dat$paper.ID)

for (r in 1:runs){
  print(r)
  paper.ID.list.rand = sample(upaper, size = length(upaper), replace = TRUE)
  out = NULL
  for (a in 1:length(paper.ID.list.rand)){
    tmp = subset(dat, paper.ID == paper.ID.list.rand[a])
    out = rbind(out, tmp)
  }
  #fixed effects model
  m.g.fixed <- glm(abs(d) ~pathway -1, weights = 1/d.sampling.variance, data=out,
                   family = Gamma
                   )
  s= summary(m.g.fixed)
  s.c = data.frame(s$coefficients)
  s.c <- s.c %>% rownames_to_column("category")
  s.c$run = r
  model.out= rbind(model.out, s.c)  
}

m.sum <- model.out %>%
  group_by(category) %>%
  summarize(
            p_05 = length(which(Pr...t..<0.05)),
            mean = mean(Estimate)
            )
m.sum = data.frame(m.sum)
m.sum
```

###bootstrap with fake data (gamma-distributed random numbers), preserving number of observations per study
##bootstrap and save test statistic values
```{r}
load("M.Rdata")

M = subset(M, !is.na(d))
M = subset(M, pathway != "PP to ecosystem fxn")
M$paper.ID=factor(M$paper.ID)
dat = M
dat$d = rgamma(dim(dat)[1], 2, rate = 1)

runs = 100

model.out = NULL
upaper = unique(dat$paper.ID)

for (r in 1:runs){
  print(r)
  paper.ID.list.rand = sample(upaper, size = length(upaper), replace = TRUE)
  out = NULL
  for (a in 1:length(paper.ID.list.rand)){
    tmp = subset(dat, paper.ID == paper.ID.list.rand[a])
    out = rbind(out, tmp)
  }
  #fixed effects model
  m.g.fixed <- glm(abs(d) ~pathway -1, weights = 1/d.sampling.variance, data=out,
                   family = Gamma
                   )
  s= summary(m.g.fixed)
  s.c = data.frame(s$coefficients)
  s.c <- s.c %>% rownames_to_column("category")
  s.c$run = r
  model.out= rbind(model.out, s.c)  
}

m.sum <- model.out %>%
  group_by(category) %>%
  summarize(
    p_05 = length(which(Pr...t..<0.05)),
            mean = mean(Estimate)
            )
#m.sum = data.frame(m.sum)
m.sum
```




###try using Gamma distribution with lme4. note that lme4 does not have option of specifying that weights are exact
```{r}
load("M.Rdata")
# install.packages("R2admb")
# install.packages("glmmADMB", 
#     repos=c("http://glmmadmb.r-forge.r-project.org/repos",
#             getOption("repos")),
#     type="source")
# 
# library(glmmADMB)
# install.packages("glmmTMB")
# library(glmmTMB)
M = subset(M, !is.na(d))
M = subset(M, pathway != "PP to ecosystem fxn")
M$paper.ID=factor(M$paper.ID)
dat = M
dat$d = dat$d+0.000001

dat$paper.ID=factor(dat$paper.ID)
#gamma with ONLY random effects (no fixed effects) runs, but with warning about "model failed to converge", despite paper.ID being factor. 
# res.lmer.rand <- glmer(abs(d) ~ (1 | paper.ID), weights = 1/d.sampling.variance, data=dat_rep,
#                  control=glmerControl(check.nobs.vs.nlev="ignore", check.nobs.vs.nRE="ignore"),
#                  family = Gamma(link = "log")
#                  )
# Model failed to converge with max|grad| = 0.0736871 (tol = 0.001, component 1)Model is nearly unidentifiable: very large eigenvalue
#  - Rescale variables?> 


#gamma without log link doesn't work
# res.lmer.g.nocontrol <- glmer(abs(d) ~ pathway -1 + (1 | paper.ID), weights = 1/d.sampling.variance, data=dat,
#                  family = Gamma
#                  )
#Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit = 100L,  : 
#  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
#this page from Bolker (one of lme4 authors) indicates error results from NaN values, suggests using log link for gamma: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q1/024453.html

#however, gamma with log link also doesn't work. 
# res.lmer.g <- glmer(abs(d) ~ pathway -1 + (1 | paper.ID), weights = 1/d.sampling.variance, data=dat,
#                  family = Gamma(link = "log")                 )
#Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit = 100L,  : 
#  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate

#this works (with only fixed effect), so there is something about the random effects that is problematic
# res.lmer.pathway <- glm(abs(d) ~ pathway-1 , weights = 1/d.sampling.variance, data=dat,
#                  family = Gamma(link = "log")
# )
# summary(res.lmer.pathway)


# dat_rep = do.call("rbind", replicate(100, dat, simplify = FALSE))
# dat_rep$d = sample(dat_rep$d, replace = TRUE)
# dat_rep$d.sampling.variance = sample(dat_rep$d.sampling.variance, replace = TRUE)


#with synthetic data (that have proportion of observations per study as in original, get a different error):
#"unable to evaluate scaled gradientModel failed to converge: degenerate  Hessian with 1 negative eigenvalues"
#this post suggests issue may be with optimizer, but changing optimizer as recommended didn't change warning https://stackoverflow.com/questions/21344555/convergence-error-for-development-version-of-lme4
# res.lmer.g.synthetic <- glmer(abs(d) ~ pathway -1 + (1 | paper.ID), weights = 1/d.sampling.variance, data=dat_rep,
#                  family = Gamma(link = "log"),
#                  control=glmerControl(optimizer="bobyqa")
#                  )

#try one more time after equalizing sample size by paper.ID, get error message about failing to converge 
# dat_rep$paper.ID = factor(rep(seq(1,26),350))
# res.lmer.g.synthetic <- glmer(abs(d) ~ pathway -1 + (1 | paper.ID), weights = 1/d.sampling.variance, data=dat_rep,
#                  family = Gamma(link = "log"),
#                  control=glmerControl(optimizer="bobyqa")
#                  )
# "Model failed to converge with max|grad| = 238.147 (tol = 0.001, component 1)Model is nearly unidentifiable: very large eigenvalue
#  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
#  - Rescale variables?> "



#try with inverse gaussian
# res.glmer.inverse.gaussian <- glmer(abs(d) ~ pathway -1 + (1 | paper.ID), weights = 1/d.sampling.variance, data=dat,
#                  family = inverse.gaussian)


#try with quasi -- can't be used
# res.glmer.quasi <- glmer(abs(d) ~ pathway -1 + (1 | paper.ID), weights = 1/d.sampling.variance, data=dat,
#                  family = quasi)


# res.lmer.g <- glmmadmb(abs(d) ~ pathway + (1 | paper.ID), weights = 1/d.sampling.variance, data=dat,
#                  family = "gamma"
# )

# res.lmer.g <- glmmTMB(abs(d) ~ pathway + (1 | paper.ID), weights = 1/d.sampling.variance, data=dat,
#                  family = "Gamma"
# )


#gamma without log link doesn't work
# res.lmer.g.nolog <- glmer(abs(d) ~ pathway + (1 | paper.ID), weights = 1/d.sampling.variance, data=dat,
#                  control=glmerControl(check.nobs.vs.nlev="ignore", check.nobs.vs.nRE="ignore"),
#                  family = Gamma
# )


# tt <- getME(res.lmer.g,"theta")
# ll <- getME(res.lmer.g,"lower")
# min(tt[ll==0])
# 
# summary(res.lmer.g)



```

###try using weibull with gamlss -- haven't gotten this to work with our data
#https://stats.stackexchange.com/questions/225457/fit-glm-for-weibull-family
```{r}

load("M.Rdata")
M = subset(M, !is.na(d))
M = subset(M, pathway != "PP to ecosystem fxn")
dat = M
dat$d = dat$d+0.000001

#this works
dat<-rWEI(100, mu=10, sigma=2)
gamlss(dat~1, family=WEI)

#this throws an error "response variable out of range"
# d = dat$d
# gamlss(d~1, family=WEI)

```



###run mixed models, for pathway and for measure
##keeping for now but these may not be valid because assume normality
```{r}

# load("M.Rdata")
# # 
# M.max = subset(M, d.sampling.variance == max(M$d.sampling.variance, na.rm=TRUE))
# M.max
# #note: removing observation with (high) outlier variance, because otherwise cannot obtain stable results. If this is not satisfactory, then we could switch to using e.g. lme4, though metafor author has some criticisms of going that route:
# #http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer
# M = subset(M, d.sampling.variance != max(M$d.sampling.variance, na.rm=TRUE))
# M = subset(M, !is.na(d))
# length(unique(M$paper.ID))#number of papers
# # length(unique(M$data.to.use))#number of data types
# table(M$data.to.use)#table of variables represented by each data type
# out = M
# 
# #for model with two predictors, estimated effects are relative to one condition, making it difficult to determine (even when subtracting one so that model has intercept of zero)
# m.pathway.measure = rma.uni(abs(d) ~ pathway:measure.general -1,
#              vi = d.sampling.variance,
#              slab = paper.ID,
#              data = out)
# m.pathway.measure
# #http://www.metafor-project.org/doku.php/tips:multiple_factors_interactions#model_with_interaction
# summary(glht(m.pathway.measure, linfct=contrMat(c(
#   "abund biomass to ecosystem fxn:biogeochemical cycles"=1,
#   "morbidity to ecosystem fxn:biogeochemical cycles"=1,
#   "unknown to ecosystem fxn:biogeochemical cycles"=1,
#   "abund biomass to ecosystem fxn:primary production"=1,
#   "abund biomass to ecosystem fxn:secondary production"=1), type="Tukey")), test=adjusted("none"))
# 
# #model with pathway as predictor
# m.pathway = rma.uni(abs(d) ~ pathway -1,
#              vi = d.sampling.variance,
#              slab = paper.ID,
#              data = out)
# m.pathway
# save(m.pathway, file = "m.pathway.Rdata")
# 
# #model with measure as predictor
# m.measure = rma.uni(abs(d) ~ factor(measure.general)-1,
#              vi = d.sampling.variance,
#              slab = paper.ID,
#              data = out)
# m.measure
# #http://www.metafor-project.org/doku.php/tips:testing_factors_lincoms#all_pairwise_comparisons
# #this glht throws error:
# # Error in glht.matrix(m.measure, linfct = cbind(contrMat(c(`biogeochemical cycles` = 1,  :
# #   ‘ncol(linfct)’ is not equal to ‘length(coef(model))’
# 
# # summary(glht(m.measure, linfct=cbind(contrMat(c("biogeochemical cycles"=1,
# #                                           "primary production"=1,
# #                                           "secondary production"=1), type="Tukey"), 0, 0)), test=adjusted("none"))
# #http://www.metafor-project.org/doku.php/tips:testing_factors_lincoms#all_pairwise_comparisons
# 
# save(m.measure, file = "m.measure.Rdata")

# #intercept-only model, may want to use this to estimate overall effect
# m.rand = rma.uni(abs(d) ~ 1,
#              vi = d.sampling.variance,
#              slab = paper.ID,
#              data = out)

```

###visualize model results for pathway -- barplot with standard errors 
```{r pathway_errorbar}

# require(cowplot)
# 
# load("m.pathway.Rdata")
# load("res.lme.pathway.Rdata")
# s = summary(m.pathway)
# estimate = s$beta
# se = s$se
# rn = row.names(s$beta)
# rnout = NULL
# for (a in 1:length(rn)){
#   tmp = strsplit(rn[a], "pathway")[[1]][2]
#   rnout = c(rnout, tmp)
# }
# rnout[rnout == "abund biomass to ecosystem fxn"]="abundance"
# rnout[rnout == "morbidity to ecosystem fxn"]="phenotype"
# rnout[rnout == "unknown to ecosystem fxn"]="unknown"
# df = data.frame(effect = estimate,
#                 se = se,
#                 pathway = rnout)
# p1 <- ggplot(df, aes(x = pathway, y = effect)) +  
#   geom_bar(stat="identity", color="black", 
#            position=position_dodge()) +
#   geom_errorbar(aes(ymin=effect-se, 
#                     ymax=effect+se), width=.2,
#                  position=position_dodge(.9)) +
#   scale_fill_grey()+
#     #theme(axis.text.x = element_text(angle = 90, hjust = 1))+
#   
#   xlab("pathway")+
#   ylab("Average absolute effect size (+-SE)")
# p1
# save_plot( "Figure.effect.pathway.jpg", p1, nrow = 1, dpi = 600)

```


###visualize model results for measure -- barplot with standard errors 
```{r measure_errorbar}

# require(cowplot)
# 
# load("m.measure.Rdata")
# s = summary(m.measure)
# estimate = s$beta
# se = s$se
# rn = row.names(s$beta)
# rnout = NULL
# for (a in 1:length(rn)){
#   tmp = strsplit(rn[a], "general)")[[1]][2]
#   rnout = c(rnout, tmp)
# }
# # rnout[rnout == "abund biomass to ecosystem fxn"]="abundance"
# # rnout[rnout == "morbidity to ecosystem fxn"]="phenotype"
# # rnout[rnout == "unknown to ecosystem fxn"]="unknown"
# df = data.frame(effect = estimate,
#                 se = se,
#                 measure = rnout)
# p1 <- ggplot(df, aes(x = measure, y = effect)) +  
#   geom_bar(stat="identity", color="black", 
#            position=position_dodge()) +
#   geom_errorbar(aes(ymin=effect-se, 
#                     ymax=effect+se), width=.2,
#                  position=position_dodge(.9)) +
#   scale_fill_grey()+
#     #theme(axis.text.x = element_text(angle = 90, hjust = 1))+
#   
#   xlab("measure")+
#   ylab("Average absolute effect size (+-SE)")
# p1
# save_plot( "Figure.effect.measure.jpg", p1, nrow = 1, dpi = 600)
```



###visualize model results for pathway -- barplot with standard errors -- absolute value
```{r pathway_errorbar_abs}
require(cowplot)
load("M.Rdata")
M = subset(M, !is.na(d))
M = subset(M, pathway != "PP to ecosystem fxn")
M$paper.ID=factor(M$paper.ID)
dat = M
dat$d = dat$d+0.000001

#use as sample size number of years
dat2 <- dat %>%
  group_by(pathway) %>%
  summarize(abs = mean(abs(d)),
         sd.abs = sd(abs(d)),# d = log.odds.ratio * sqrt(3)/pi,
         se.abs = sd.abs/sqrt(length(d))
         # var_d=(ratio.sd)^2
         )

dat2 = data.frame(dat2)
# dat2 <- dat %>%
#   group_by(pathway) %>%
#   summarize(log.abs = mean(log(abs(d))),
#          sd.log.abs = sd(log(abs(d))),# d = log.odds.ratio * sqrt(3)/pi,
#          se.log.abs = sd.log.abs/sqrt(length(d))
#          # var_d=(ratio.sd)^2
#          )


# load("res.lme.pathway.Rdata")
# s = summary(res.lme.pathway)
# estimate = s$beta
# se = s$se
# rn = row.names(s$beta)
# rnout = NULL
# for (a in 1:length(rn)){
#   tmp = strsplit(rn[a], "pathway")[[1]][2]
#   rnout = c(rnout, tmp)
# }
dat2$pathway=as.character(dat2$pathway)
dat2$pathway[dat2$pathway == "abund biomass to ecosystem fxn"]="abundance"
dat2$pathway[dat2$pathway == "morbidity to ecosystem fxn"]="phenotype"
dat2$pathway[dat2$pathway == "unknown to ecosystem fxn"]="unknown"
df = data.frame(effect = dat2$abs,
                se = dat2$se.abs,
                pathway = dat2$pathway)
p1 <- ggplot(df, aes(x = pathway, y = effect)) +
  geom_bar(stat="identity", color="black",
           position=position_dodge()) +
  geom_errorbar(aes(ymin=effect-se,
                    ymax=effect+se), width=.2,
                 position=position_dodge(.9)) +
  scale_fill_grey()+
    #theme(axis.text.x = element_text(angle = 90, hjust = 1))+

  xlab("pathway")+
  ylab("Average absolute effect size (+-SE)")
p1
# save_plot( "Figure.effect.pathway.jpg", p1, nrow = 1, dpi = 600)

```


###visualize model results for measure -- barplot with standard errors -- absolute value
```{r measure_errorbar_abs}
require(cowplot)
load("M.Rdata")
M = subset(M, !is.na(d))
M = subset(M, pathway != "PP to ecosystem fxn")
M$paper.ID=factor(M$paper.ID)
dat = M
dat$d = dat$d+0.000001

#use as sample size number of years
dat2 <- dat %>%
  group_by(measure.general) %>%
  summarize(abs = mean(abs(d)),
         sd.abs = sd(abs(d)),# d = log.odds.ratio * sqrt(3)/pi,
         se.abs = sd.abs/sqrt(length(d))
         # var_d=(ratio.sd)^2
         )

dat2 = data.frame(dat2)

df = data.frame(effect = dat2$abs,
                se = dat2$se.abs,
                measure = dat2$measure.general)
p1 <- ggplot(df, aes(x = measure, y = effect)) +
  geom_bar(stat="identity", color="black",
           position=position_dodge()) +
  geom_errorbar(aes(ymin=effect-se,
                    ymax=effect+se), width=.2,
                 position=position_dodge(.9)) +
  scale_fill_grey()+
    #theme(axis.text.x = element_text(angle = 90, hjust = 1))+

  xlab("measure")+
  ylab("Average absolute effect size (+-SE)")
p1
# save_plot( "Figure.effect.pathway.jpg", p1, nrow = 1, dpi = 600)

```





##qualitative analyses

###pathogen vs. host test for significant associations using chi-square
```{r}
load("M.Rdata")
#get one row per study
PH = M[,c("paper.ID", "Pathogen.kingdom", "Host.kingdom", "System")]
PH = PH[!duplicated(PH), ]
dim(PH)
PH = subset(PH, Pathogen.kingdom !="multiple")
dim(PH)[1]
PH = subset(PH, Host.kingdom !="multiple")
dim(PH)

PH = subset(PH, Pathogen.kingdom !="not reported")
dim(PH)[1]

#make table of counts of each combination of two variables
# tbl =table(as.character(PH$Pathogen.kingdom), as.character(PH$Host.kingdom))
# dimnames(tbl) <- list(pathogen = c("animal", "bacteria", "eukaryote", "fungus",
#                                  "plant", "virus" ),
#                     host = c("animal", "bacteria", "eukaryote", "plant", "prokaryote"))
#https://4va.github.io/biodatasci/r-stats.html
PH$Pathogen.kingdom=as.character(PH$Pathogen.kingdom)
PH$Host.kingdom = as.character(PH$Host.kingdom)
tbl <- xtabs(~Host.kingdom+ Pathogen.kingdom, data=PH)
tbl
jpeg("Figure.A.2.host.pathogen.jpeg", width = 9, height = 10, units = 'in', res = 300)
#this piece required some minor adjustments
# par(mar=c(5, 24, 5, 5.7) + 0.1, ps = 8)# 

#par(mar=c(5,24,5,5.7))
par(mar=rep(5,4))
assocplot(tbl,
          ylab = "Pathogen or parasite",
          xlab = "Host")
dev.off()#need to do this to finish the plot


#chisq.test(tbl) 
(X <- chisq.test(tbl, simulate.p.value = TRUE))
#(X <- chisq.test(tbl))
#barplot(X$observed, X$expected, beside = TRUE)
#
save(PH, file = "PH.Rdata")
tbl.host = table(PH$Host.kingdom)
tbl.host = data.frame(tbl.host)
tbl.host$frac = round(tbl.host$Freq/sum(tbl.host$Freq), digits = 3)
print("percent of hosts")
100*tbl.host$frac
tbl.p = table(PH$Pathogen.kingdom)
tbl.p = data.frame(tbl.p)
tbl.p$frac = round(tbl.p$Freq/sum(tbl.p$Freq), digits = 3)
print("percent of pathogens")
tbl.p

#balloonplot(t(tbl))
```

##read in studies data and make graph of pathogen frequency for each kingdom of hosts
```{r}
load("PH.Rdata")

plot<- ggplot(data = PH, mapping = aes(x = Pathogen.kingdom))+
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  facet_wrap(.~Host.kingdom)+
  ylab("Number of studies")+
  xlab("Pathogen taxa")
#    ggtitle("count of pathogen-host combinations")

plot
ggsave(plot = plot, filename = paste0("Figure.A.1", 
                                      "pathogen-host-facet", ".jpg"))
```

###make contingency table of pathogen vs. ecosystem type, and host vs. ecosystem
```{r}
load("PH.Rdata")
#make table of counts of each combination of two variables
#pathogen vs. system
PH$Pathogen.kingdom = as.character(PH$Pathogen.kingdom)
PH$System = as.character(PH$System)
PH$Pathogen.kingdom[PH$Pathogen.kingdom=="eukaryote"]="euk."
tbl <- xtabs(~Pathogen.kingdom+ System, data=PH)

jpeg("Figure.A.pathogen.system.jpeg", width = 9, height = 10, units = 'in', res = 300)
#this piece required some minor adjustments
par(mar=rep(5,4))
assocplot(tbl,
          xlab = "Pathogen or parasite",
          ylab = "Ecosystem type")
dev.off()#need to do this to finish the plot

# tbl =table(as.character(PH$Pathogen.kingdom), as.character(PH$System))
X = chisq.test(tbl, simulate.p.value = TRUE)

#host vs. system
tbl <- xtabs(~Host.kingdom+ System, data=PH)
jpeg("Figure.A.host.system.jpeg", width = 9, height = 10, units = 'in', res = 300)
#this piece required some minor adjustments
par(mar=rep(5,4))
assocplot(tbl,
          xlab = "Host",
          ylab = "Ecosystem type")
dev.off()#need to do this to finish the plot

# tbl =table(as.character(PH$Host.kingdom), as.character(PH$System))
X = chisq.test(tbl, simulate.p.value = TRUE)

PH_t = subset(PH, System == "terrestrial")
tbl.h = table(as.character(PH_t$Host.kingdom))
tbl.h = data.frame(tbl.h)
tbl.h$frac = round(tbl.h$Freq/sum(tbl.h$Freq), digits = 3)

tbl.p = table(as.character(PH_t$Pathogen.kingdom))
tbl.p = data.frame(tbl.p)
tbl.p$frac = round(tbl.p$Freq/sum(tbl.p$Freq), digits = 3)
tbl.p

#aquatic
PH_a = subset(PH, System == "aquatic")
tbl.h = table(as.character(PH_a$Host.kingdom))
tbl.h = data.frame(tbl.h)
tbl.h$frac = round(tbl.h$Freq/sum(tbl.h$Freq), digits = 3)

tbl.p = table(as.character(PH_a$Pathogen.kingdom))
tbl.p = data.frame(tbl.p)
tbl.p$frac = round(tbl.p$Freq/sum(tbl.p$Freq), digits = 3)
tbl.p

require(cowplot)

plot1<- ggplot(data = PH, mapping = aes(x = Pathogen.kingdom))+
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  facet_wrap(.~System, nrow = 2)+
  ylab("Number of studies")+
  xlab("Pathogen taxa")

#plot
#ggsave(plot = plot, filename = paste0("Figure.A.2", 
 #                                     "pathogen-ecosystem-type", ".jpg"))

plot2<- ggplot(data = PH, mapping = aes(x = Host.kingdom))+
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  facet_wrap(.~System, nrow = 2)+
  ylab("Number of studies")+
  xlab("Host taxa")

p = plot_grid(plot1, plot2, labels = c("A", "B"), nrow = 2, align = "v")
save_plot( "Figure.A.2.jpg", p, nrow = 2, dpi = 600)


# plot
# ggsave(plot = plot, filename = paste0("Figure.A.3", 
#                                       "host-ecosystem-type", ".jpg"))


# PHsum <- PH %>%
#   group_by(System, Pathogen.kingdom) %>%
#   summarize(count = n(),
#             count_pathogen = n(Pathogen.kingdom),
#             frac_pathogen = count_pathogen/count_system)

```


###chi squared test and plots for pathogen and host taxa vs. pathway to ecosystem function
```{r}
load("M.Rdata")
require(cowplot)
#get one row per study
PHP = M[,c("paper.ID", "Pathogen.kingdom", "Host.kingdom", "System", "pathway")]
PHP = PHP[!duplicated(PHP), ]
PHP = subset(PHP, Pathogen.kingdom !="multiple")
PHP = subset(PHP, Host.kingdom !="multiple")
PHP = subset(PHP, Pathogen.kingdom !="not reported")

PHP = subset(PHP, pathway %in% c("unknown to ecosystem fxn",
                                 "abund biomass to ecosystem fxn", 
             "morbidity to ecosystem fxn", 
             "PP to ecosystem fxn"))
df = PHP
df$pathway = as.character(df$pathway)
df$Pathogen.kingdom = as.character(df$Pathogen.kingdom)
df$pathway[df$pathway == "unknown to ecosystem fxn"]="ukn.->eco."
df$pathway[df$pathway == "abund biomass to ecosystem fxn"]="abundance->eco."
df$pathway[df$pathway == "morbidity to ecosystem fxn"]="phenotype->eco."
df$pathway[df$pathway == "PP to ecosystem fxn"]="PP->eco."

df$Pathogen.kingdom[df$Pathogen.kingdom=="bacteria"] ="bact."
df$Pathogen.kingdom[df$Pathogen.kingdom=="eukaryote"] ="euk."

df$Pathogen.kingdom[df$Pathogen.kingdom=="fungus"] ="fung."
#check that records are correct
test = subset(df, Pathogen.kingdom=="eukaryote" & pathway == "PP->eco.")
print("chi sq pathogen vs. pathway")

df$Pathogen.kingdom=as.character(df$Pathogen.kingdom)
df$pathway=as.character(df$pathway)

df$pathway <- factor(df$pathway, levels = c("abundance->eco.", 
             "phenotype->eco.", 
             "ukn.->eco.",
             "PP->eco."))

tbl_pathway <- xtabs(~pathway, data = df)
tbl <- xtabs(~Pathogen.kingdom+ pathway, data=df)
jpeg("Figure.A.pathogen.pathway.jpeg", width = 9, height = 10, units = 'in', res = 300)
par(mar=rep(5,4))
assocplot(tbl,
          xlab = "Pathogen",
          ylab = "Pathway")
dev.off()#need to do this to finish the plot

Xp = chisq.test(tbl, simulate.p.value = TRUE)

##Host and pathway
df$Host.kingdom = as.character(df$Host.kingdom)

print("chi sq host vs. pathway")
tbl <- xtabs(~Host.kingdom+ pathway, data=df)
jpeg("Figure.A.host.pathway.jpeg", width = 9, height = 10, units = 'in', res = 300)
par(mar=rep(5,4))
assocplot(tbl,
          xlab = "Host",
          ylab = "Pathway")
dev.off()#need to do this to finish the plot

Xh = chisq.test(tbl, simulate.p.value = TRUE)

#levels(dfr$cyl_f)

#abundance -- pathogen
df_a = subset(df, pathway == "abund.->eco.")
tbl = table(as.character(df_a$Pathogen.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

#abundance -- host
df_a = subset(df, pathway == "abund.->eco.")
tbl = table(as.character(df_a$Host.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

#morbid -- pathogen
df_a = subset(df, pathway == "phenotype->eco.")
tbl = table(as.character(df_a$Pathogen.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

#morbid -- host 
df_a = subset(df, pathway == "phenotype->eco.")
tbl = table(as.character(df_a$Host.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

#PP -- pathogen 
df_a = subset(df, pathway == "PP->eco.")
tbl = table(as.character(df_a$Pathogen.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

#PP -- host
df_a = subset(df, pathway == "PP->eco.")
tbl = table(as.character(df_a$Host.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

plot<- ggplot(data = df, mapping = aes(x = Pathogen.kingdom))+
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  facet_wrap(.~pathway, ncol = 1)+
  ylab("Number of studies")+
  xlab("Pathogen taxa")
 
plot
save_plot( "Figure.A.3.pathogen.pathway.jpg", plot, nrow = 1, dpi = 600, base_height = 6)

#plot for host and pathway
plot<- ggplot(data = df, mapping = aes(x = Host.kingdom))+
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  facet_wrap(.~pathway, ncol = 1)+
  ylab("Number of studies")+
  xlab("Host taxa")
 
plot
save_plot( "Figure.A.4.host.pathway.jpg", plot, nrow = 1, dpi = 600, base_height = 6)

```

###run chi squared test and make plots for pathogen and host kingdom vs. ecosystem process
```{r}
load("M.Rdata")
#get one row per study
PHP = M[,c("paper.ID", "Pathogen.kingdom", "Host.kingdom", "System", "measure.general")]
PHP = PHP[!duplicated(PHP), ]
PHP = subset(PHP, Pathogen.kingdom !="multiple")
PHP = subset(PHP, Host.kingdom !="multiple")
PHP = subset(PHP, Pathogen.kingdom !="not reported")

PHP = subset(PHP, measure.general %in% c("primary production",
                                 "secondary production", 
             "biogeochemical cycles"))
df = PHP

df$measure.general <- factor(df$measure.general, levels = c("primary production", 
             "secondary production", 
             "biogeochemical cycles"))

df$measure.general = as.character(df$measure.general)
df$Pathogen.kingdom=as.character(df$Pathogen.kingdom)
df$Host.kingdom=as.character(df$Host.kingdom)
df$Pathogen.kingdom[df$Pathogen.kingdom=="bacteria"] ="bact."
df$Pathogen.kingdom[df$Pathogen.kingdom=="eukaryote"] ="euk."

df$measure.general <- factor(df$measure.general, levels = c("primary production",
  "secondary production", 
  "biogeochemical cycles"))
tbl_fxn <- xtabs(~measure.general, data=df)
tbl <- xtabs(~Pathogen.kingdom+ measure.general, data=df)
jpeg("Figure.A.pathogen.ecosystem.function.jpeg", width = 9, height = 10, units = 'in', res = 300)
par(mar=rep(5,4))
assocplot(tbl,
          xlab = "Pathogen",
          ylab = "Ecosystem function")
dev.off()#need to do this to finish the plot

print("chi sq pathogen vs. measure")
Xp = chisq.test(tbl, simulate.p.value = TRUE)

print("chi sq host vs. measure")
tbl <- xtabs(~Host.kingdom+ measure.general, data=df)
Xh = chisq.test(tbl, simulate.p.value = TRUE)

jpeg("Figure.A.host.ecosystem.function.jpeg", width = 9, height = 10, units = 'in', res = 300)
par(mar=rep(5,4))
assocplot(tbl,
          xlab = "Host",
          ylab = "Ecosystem function")
dev.off()#need to do this to finish the plot

#primary -- pathogen 
df_a = subset(df, measure.general == "primary production")
tbl = table(as.character(df_a$Pathogen.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

#secondary -- pathogen 
df_a = subset(df, measure.general == "secondary production")
tbl = table(as.character(df_a$Pathogen.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

#biogeo -- pathogen 
df_a = subset(df, measure.general == "biogeochemical cycles")
tbl = table(as.character(df_a$Pathogen.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

#primary -- host 
df_a = subset(df, measure.general == "primary production")
tbl = table(as.character(df_a$Host.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

#secondary -- host 
df_a = subset(df, measure.general == "secondary production")
tbl = table(as.character(df_a$Host.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

df_check = subset(M, Host.kingdom == "plant" & measure.general == "secondary production")
df_check$measure.specific....outcome.variable

#biogeoche -- host 
df_a = subset(df, measure.general == "biogeochemical cycles")
tbl = table(as.character(df_a$Host.kingdom))
tbl = data.frame(tbl)
tbl$frac = round(tbl$Freq/sum(tbl$Freq), digits = 3)
tbl

plot<- ggplot(data = df, mapping = aes(x = Pathogen.kingdom))+
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  facet_wrap(.~measure.general, ncol = 1)+
  ylab("Number of studies")+
  xlab("Pathogen taxa")
plot

save_plot( "Figure.A.5.pathogen.measure.jpg", plot, nrow = 1, dpi = 600, base_height = 6)

#host -- ecosystem measure
plot<- ggplot(data = df, mapping = aes(x = Host.kingdom))+
  geom_bar()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  facet_wrap(.~measure.general, ncol = 1)+
  ylab("Number of studies")+
  xlab("Host taxa")
plot

save_plot( "Figure.A.6.pathogen.measure.jpg", plot, nrow = 1, dpi = 600, base_height = 6)


```




#####SCRATCH work below here. 

###make plot of frequency of pathogen kingdom for each pathway from host/community to ecosystem process
###commenting this part out for now, will do using M
```{r}

# load("S.Rdata")
# names(S)[names(S)=="abund.biomass.to.ecosystem.fxn"]="var_1"
# names(S)[names(S)=="morbidity.to.ecosystem.fxn"]="var_2"
# names(S)[names(S)=="unknown.to.ecosystem.fxn"]="var_3"
# 
# tolong = names(S)[c(18:20)]
# dim(S)[1]
# S = subset(S, exclude != "1")
# dim(S)[1]
# 
# #S = subset(S, ID == "315")
# 
# S = S[1,]
# 
# S.long<-reshape(S, 
#                 varying=tolong, 
#                 direction="long", 
#                 idvar="ID",
#                 times = tolong,
#                 sep="_")
# 
# i1 = which(S.long$time == 1)
# pathway = rep("unassigned", dim(S.long)[1])
# pathway[i1]="abund/biomass --> ecosystem"
# i2 = which(S.long$time == 2)
# pathway[i2]="morbidity --> ecosystem"
# i3 = which(S.long$time == 3)
# pathway[i3]="unknown --> ecosystem"
# S.long$pathway = pathway
# S.long = subset(S.long, var == 1)
# plot<- ggplot(data = S.long, mapping = aes(x = Pathogen.kingdom))+
#   geom_bar()+
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))+
#   facet_wrap(.~pathway)+
#   ylab("number of studies")+
#     ggtitle("frequency of pathogen - pathway pairs")
# # 
# plot

```

####read in data and summarize
```{r}
P = read.csv("meta_data_20180724 - measures.csv")
P = subset(P, exclude.as.ecosystem.measure !=1)
names(P)
#check ones that are empty
tmp = subset(P,measure.general == "")
tmp
pathway.number = rep(3, dim(P)[1])
pathway.number[(P$pathway=="abund biomass to ecosystem fxn" | P$pathway == "morbidity to ecosystem fxn")]=2
pathway.number[(P$pathway=="PP to ecosystem fxn" | P$pathway == "PP to abund biomass" 
                | P$pathway == "PP to morbidity")]=1

P$pathway.number = pathway.number
P = subset(P, measure.general!="")
P$measure.general = trimws(P$measure.general)
P$measure.specific....outcome.variable = trimws(P$measure.specific....outcome.variable)

#check out "community"
Pcom = subset(P, measure.general == "community")
sort(unique(P$measure.general))

#community.list = c("community")

P1 <- P %>%
  group_by(paper.ID, pathway.number, pathway, measure.general) %>%
  summarize(measure.general.count = n())

P1$measure.general.presence = 1#if there is at least one measure like this

P2 <- P1 %>%
  group_by(pathway.number, pathway, measure.general) %>%
  summarize(measure.general.count.across.papers = sum(measure.general.presence))

P2 = data.frame(P2)
P2 = P2[
  with(P2, order(pathway.number, pathway, measure.general.count.across.papers)),
]
P2
write.csv(P2, file = "summary.20180815.csv")
```

###manually summarize data as relating to host or community, then read back in and use to reclassify
```{r}
P$measure.general.previous = P$measure.general
P$community = NA
P$host = NA
Pr = read.csv("summary.20180815_reclassified.csv")

names(Pr)
Pr = subset(Pr, reclassify !="")
upathway = unique(Pr$pathway)
a = 2
for (a in 1:length(upathway)){
  Pr.tmp = subset(Pr, pathway == upathway[a])
  umeasure.general = unique(Pr.tmp$measure.general)#for each unique measure.general
  for (b in 1:length(umeasure.general)){
    Pr.tmp.measure.general = subset(Pr.tmp, measure.general == umeasure.general[b])
    inds = which(as.character(P$pathway) == as.character(upathway[a]) & as.character(P$measure.general) == as.character(umeasure.general[b]))
    P$measure.general[inds]=as.character(Pr.tmp.measure.general$reclassify)
    P$community[inds]= Pr.tmp.measure.general$community
    P$host[inds]=Pr.tmp.measure.general$host
  }
}
save(P, file = "P.Rdata")
```

###summarize again P having reclassified
```{r}
load("P.Rdata")
#order, select fields, and output
Psum_simple <- P %>%
  group_by(pathway.number, pathway, measure.general, measure.specific....outcome.variable, community, host) %>%
  summarize(count = n())

Psum_simple = Psum_simple[
  with(Psum_simple, order(pathway, measure.general)),
]
write.csv(Psum_simple, file = "P_raw_summarized.csv")

#now summarize more
Pa <- P %>%
  group_by(paper.ID, pathway.number, pathway, measure.general, community, host) %>%
  summarize(measure.general.count = n())

Pa$measure.general.presence = 1#if there is at least one measure like this

Pb <- Pa %>%
  group_by(pathway.number, pathway, measure.general, community, host) %>%
  summarize(measure.general.count.across.papers = sum(measure.general.presence))

Pb = data.frame(Pb)
Pb = Pb[
  with(Pb, order(pathway.number, pathway, measure.general.count.across.papers)),
]

write.csv(Pb, file = "P.summary.reclass.20180815.csv")

#finally, summarize across papers by pathway and measure
```

